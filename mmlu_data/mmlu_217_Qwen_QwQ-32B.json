{
    "doc_id": "mmlu_217_Qwen_QwQ-32B",
    "metadata": {
        "model_id": "Qwen/QwQ-32B",
        "subject": "moral_scenarios",
        "correct_answer": "Not wrong, Not wrong"
    },
    "raw_text": {
        "question": "For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I bought an old pick-up truck for work. Scenario 2 | I looked up at the gorgeous waterfall and threw a rock at it.",
        "response": "Okay, so I need to figure out which of these two scenarios involves the main character doing something clearly morally wrong according to ordinary US standards in 2020. Let me start by breaking down each scenario.\n\nScenario 1: \"I bought an old pick-up truck for work.\" Hmm, buying a truck for work seems pretty normal. People buy vehicles for work all the time. Maybe the truck is old, so maybe it's not the most environmentally friendly? But is that considered morally wrong? I mean, unless there's some hidden detail like stealing the truck or something, but the scenario doesn't say that. So probably not morally wrong. Maybe some might think it's not eco-friendly, but is that a moral wrong? Maybe not a clear-cut issue.\n\nScenario 2: \"I looked up at the gorgeous waterfall and threw a rock at it.\" Throwing a rock at a waterfall... Well, waterfalls are natural attractions. If it's in a park or a protected area, throwing rocks might be damaging the environment or violating park rules. But is that a moral wrong? Trespassing or vandalism could be illegal, but morally, damaging nature for no reason might be considered wrong. But is it \"clearly\" wrong? Maybe. People might think it's irresponsible or disrespectful to nature. But compared to Scenario 1, which seems neutral, this one might be the one where the action is wrong.\n\nWait, but maybe in Scenario 1, if the truck is old, maybe it's polluting more? But again, unless it's illegal emissions or something, but buying an old truck isn't inherently wrong. The action of buying itself isn't wrong. So Scenario 2's action of throwing a rock at a waterfall could be seen as vandalism or damaging public property/nature, which is against common morals. So probably Scenario 2 is the morally wrong one.\n</think>\n\nAccording to ordinary moral standards in the US as of 2020, **Scenario 2** involves the main character doing something clearly morally wrong. Here's the breakdown:\n\n### **Scenario 1**:  \nBuying an old pick-up truck for work is a neutral or even pragmatic action. While some might debate environmental impacts (e.g., older vehicles may emit more pollutants), purchasing a used vehicle for work is not inherently morally wrong. It is a common, legally permissible, and socially acceptable choice. No clear moral violation occurs here.\n\n### **Scenario 2**:  \nThrowing a rock at a waterfall, especially if it is a natural or protected site, is morally problematic. This action could damage the environment, disrupt ecosystems, or violate park rules (e.g., damaging public property). Such behavior is generally seen as irresponsible, disrespectful to nature, and potentially harmful without justification. Most people would view this as a needless act of vandalism or carelessness, crossing ordinary moral boundaries.\n\n### **Conclusion**:  \nScenario 2\u2019s action is clearly morally wrong by typical US standards, while Scenario 1 is morally neutral."
    },
    "nodes": [
        {
            "id": "ctx0",
            "annotation": false,
            "start": 0,
            "end": 172,
            "label": "context",
            "text": "For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? ",
            "source": "question"
        },
        {
            "id": "ctx1",
            "annotation": false,
            "start": 172,
            "end": 225,
            "label": "context",
            "text": "Scenario 1 | I bought an old pick-up truck for work. ",
            "source": "question"
        },
        {
            "id": "ctx2",
            "annotation": false,
            "start": 225,
            "end": 299,
            "label": "context",
            "text": "Scenario 2 | I looked up at the gorgeous waterfall and threw a rock at it.",
            "source": "question"
        },
        {
            "id": "resp0",
            "annotation": false,
            "start": 0,
            "end": 169,
            "label": "restatement",
            "text": "Okay, so I need to figure out which of these two scenarios involves the main character doing something clearly morally wrong according to ordinary US standards in 2020. ",
            "source": "response"
        },
        {
            "id": "resp1",
            "annotation": false,
            "start": 169,
            "end": 215,
            "label": "planning",
            "text": "Let me start by breaking down each scenario.\n\n",
            "source": "response"
        },
        {
            "id": "resp2",
            "annotation": false,
            "start": 215,
            "end": 269,
            "label": "restatement",
            "text": "Scenario 1: \"I bought an old pick-up truck for work.\" ",
            "source": "response"
        },
        {
            "id": "resp3",
            "annotation": false,
            "start": 269,
            "end": 319,
            "label": "reflection",
            "text": "Hmm, buying a truck for work seems pretty normal. ",
            "source": "response"
        },
        {
            "id": "resp4",
            "annotation": false,
            "start": 319,
            "end": 362,
            "label": "fact",
            "text": "People buy vehicles for work all the time. ",
            "source": "response"
        },
        {
            "id": "resp5",
            "annotation": false,
            "start": 362,
            "end": 439,
            "label": "reflection",
            "text": "Maybe the truck is old, so maybe it's not the most environmentally friendly? ",
            "source": "response"
        },
        {
            "id": "resp6",
            "annotation": false,
            "start": 439,
            "end": 477,
            "label": "reflection",
            "text": "But is that considered morally wrong? ",
            "source": "response"
        },
        {
            "id": "resp7",
            "annotation": false,
            "start": 477,
            "end": 592,
            "label": "reasoning",
            "text": "I mean, unless there's some hidden detail like stealing the truck or something, but the scenario doesn't say that. ",
            "source": "response"
        },
        {
            "id": "resp8",
            "annotation": false,
            "start": 592,
            "end": 623,
            "label": "reasoning",
            "text": "So probably not morally wrong. ",
            "source": "response"
        },
        {
            "id": "resp9",
            "annotation": false,
            "start": 623,
            "end": 696,
            "label": "reflection",
            "text": "Maybe some might think it's not eco-friendly, but is that a moral wrong? ",
            "source": "response"
        },
        {
            "id": "resp10",
            "annotation": false,
            "start": 696,
            "end": 726,
            "label": "reflection",
            "text": "Maybe not a clear-cut issue.\n\n",
            "source": "response"
        },
        {
            "id": "resp11",
            "annotation": false,
            "start": 726,
            "end": 802,
            "label": "restatement",
            "text": "Scenario 2: \"I looked up at the gorgeous waterfall and threw a rock at it.\" ",
            "source": "response"
        },
        {
            "id": "resp12",
            "annotation": false,
            "start": 802,
            "end": 836,
            "label": "reflection",
            "text": "Throwing a rock at a waterfall... ",
            "source": "response"
        },
        {
            "id": "resp13",
            "annotation": false,
            "start": 836,
            "end": 878,
            "label": "fact",
            "text": "Well, waterfalls are natural attractions. ",
            "source": "response"
        },
        {
            "id": "resp14",
            "annotation": false,
            "start": 878,
            "end": 991,
            "label": "reasoning",
            "text": "If it's in a park or a protected area, throwing rocks might be damaging the environment or violating park rules. ",
            "source": "response"
        },
        {
            "id": "resp15",
            "annotation": false,
            "start": 991,
            "end": 1018,
            "label": "reflection",
            "text": "But is that a moral wrong? ",
            "source": "response"
        },
        {
            "id": "resp16",
            "annotation": false,
            "start": 1018,
            "end": 1131,
            "label": "reasoning",
            "text": "Trespassing or vandalism could be illegal, but morally, damaging nature for no reason might be considered wrong. ",
            "source": "response"
        },
        {
            "id": "resp17",
            "annotation": false,
            "start": 1131,
            "end": 1158,
            "label": "reflection",
            "text": "But is it \"clearly\" wrong? ",
            "source": "response"
        },
        {
            "id": "resp18",
            "annotation": false,
            "start": 1158,
            "end": 1165,
            "label": "reflection",
            "text": "Maybe. ",
            "source": "response"
        },
        {
            "id": "resp19",
            "annotation": false,
            "start": 1165,
            "end": 1231,
            "label": "reasoning",
            "text": "People might think it's irresponsible or disrespectful to nature. ",
            "source": "response"
        },
        {
            "id": "resp20",
            "annotation": false,
            "start": 1231,
            "end": 1334,
            "label": "reasoning",
            "text": "But compared to Scenario 1, which seems neutral, this one might be the one where the action is wrong.\n\n",
            "source": "response"
        },
        {
            "id": "resp21",
            "annotation": false,
            "start": 1334,
            "end": 1413,
            "label": "reflection",
            "text": "Wait, but maybe in Scenario 1, if the truck is old, maybe it's polluting more? ",
            "source": "response"
        },
        {
            "id": "resp22",
            "annotation": false,
            "start": 1413,
            "end": 1516,
            "label": "reasoning",
            "text": "But again, unless it's illegal emissions or something, but buying an old truck isn't inherently wrong. ",
            "source": "response"
        },
        {
            "id": "resp23",
            "annotation": false,
            "start": 1516,
            "end": 1557,
            "label": "reasoning",
            "text": "The action of buying itself isn't wrong. ",
            "source": "response"
        },
        {
            "id": "resp24",
            "annotation": false,
            "start": 1557,
            "end": 1709,
            "label": "reasoning",
            "text": "So Scenario 2's action of throwing a rock at a waterfall could be seen as vandalism or damaging public property/nature, which is against common morals. ",
            "source": "response"
        },
        {
            "id": "resp25",
            "annotation": false,
            "start": 1709,
            "end": 1768,
            "label": "reasoning",
            "text": "So probably Scenario 2 is the morally wrong one.\n</think>\n\n",
            "source": "response"
        },
        {
            "id": "resp26",
            "annotation": false,
            "start": 1768,
            "end": 1910,
            "label": "reasoning",
            "text": "According to ordinary moral standards in the US as of 2020, **Scenario 2** involves the main character doing something clearly morally wrong. ",
            "source": "response"
        },
        {
            "id": "resp27",
            "annotation": false,
            "start": 1910,
            "end": 1933,
            "label": "planning",
            "text": "Here's the breakdown:\n\n",
            "source": "response"
        },
        {
            "id": "resp28",
            "annotation": false,
            "start": 1933,
            "end": 2031,
            "label": "reasoning",
            "text": "### **Scenario 1**:  \nBuying an old pick-up truck for work is a neutral or even pragmatic action. ",
            "source": "response"
        },
        {
            "id": "resp29",
            "annotation": false,
            "start": 2031,
            "end": 2194,
            "label": "reasoning",
            "text": "While some might debate environmental impacts (e.g., older vehicles may emit more pollutants), purchasing a used vehicle for work is not inherently morally wrong. ",
            "source": "response"
        },
        {
            "id": "resp30",
            "annotation": false,
            "start": 2194,
            "end": 2263,
            "label": "fact",
            "text": "It is a common, legally permissible, and socially acceptable choice. ",
            "source": "response"
        },
        {
            "id": "resp31",
            "annotation": false,
            "start": 2263,
            "end": 2302,
            "label": "reasoning",
            "text": "No clear moral violation occurs here.\n\n",
            "source": "response"
        },
        {
            "id": "resp32",
            "annotation": false,
            "start": 2302,
            "end": 2429,
            "label": "reasoning",
            "text": "### **Scenario 2**:  \nThrowing a rock at a waterfall, especially if it is a natural or protected site, is morally problematic. ",
            "source": "response"
        },
        {
            "id": "resp33",
            "annotation": false,
            "start": 2429,
            "end": 2547,
            "label": "reasoning",
            "text": "This action could damage the environment, disrupt ecosystems, or violate park rules (e.g., damaging public property). ",
            "source": "response"
        },
        {
            "id": "resp34",
            "annotation": false,
            "start": 2547,
            "end": 2669,
            "label": "reasoning",
            "text": "Such behavior is generally seen as irresponsible, disrespectful to nature, and potentially harmful without justification. ",
            "source": "response"
        },
        {
            "id": "resp35",
            "annotation": false,
            "start": 2669,
            "end": 2782,
            "label": "reasoning",
            "text": "Most people would view this as a needless act of vandalism or carelessness, crossing ordinary moral boundaries.\n\n",
            "source": "response"
        },
        {
            "id": "resp36",
            "annotation": false,
            "start": 2782,
            "end": 2910,
            "label": "conclusion",
            "text": "### **Conclusion**:  \nScenario 2\u2019s action is clearly morally wrong by typical US standards, while Scenario 1 is morally neutral.",
            "source": "response"
        }
    ],
    "edges": [
        {
            "id": "e0",
            "from_node_id": "ctx0",
            "to_node_id": "resp0",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e1",
            "from_node_id": "resp0",
            "to_node_id": "resp1",
            "label": "plan:plan-subplan"
        },
        {
            "id": "e2",
            "from_node_id": "ctx1",
            "to_node_id": "resp2",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e3",
            "from_node_id": "resp1",
            "to_node_id": "resp2",
            "label": "reason:plan-step"
        },
        {
            "id": "e4",
            "from_node_id": "resp1",
            "to_node_id": "resp3",
            "label": "reason:plan-step"
        },
        {
            "id": "e5",
            "from_node_id": "resp2",
            "to_node_id": "resp3",
            "label": "evaluate:support"
        },
        {
            "id": "e6",
            "from_node_id": "resp3",
            "to_node_id": "resp4",
            "label": "reason:fact-detail"
        },
        {
            "id": "e7",
            "from_node_id": "resp3",
            "to_node_id": "resp5",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e8",
            "from_node_id": "resp4",
            "to_node_id": "resp5",
            "label": "reason:fact-detail"
        },
        {
            "id": "e9",
            "from_node_id": "resp3",
            "to_node_id": "resp6",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e10",
            "from_node_id": "resp5",
            "to_node_id": "resp6",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e11",
            "from_node_id": "resp3",
            "to_node_id": "resp7",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e12",
            "from_node_id": "resp4",
            "to_node_id": "resp7",
            "label": "reason:fact-detail"
        },
        {
            "id": "e13",
            "from_node_id": "resp5",
            "to_node_id": "resp7",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e14",
            "from_node_id": "resp5",
            "to_node_id": "resp8",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e15",
            "from_node_id": "resp6",
            "to_node_id": "resp8",
            "label": "evaluate:support"
        },
        {
            "id": "e16",
            "from_node_id": "resp7",
            "to_node_id": "resp8",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e17",
            "from_node_id": "resp5",
            "to_node_id": "resp9",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e18",
            "from_node_id": "resp6",
            "to_node_id": "resp9",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e19",
            "from_node_id": "resp8",
            "to_node_id": "resp10",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e20",
            "from_node_id": "resp9",
            "to_node_id": "resp10",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e21",
            "from_node_id": "ctx2",
            "to_node_id": "resp11",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e22",
            "from_node_id": "resp1",
            "to_node_id": "resp11",
            "label": "reason:plan-step"
        },
        {
            "id": "e23",
            "from_node_id": "resp11",
            "to_node_id": "resp12",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e24",
            "from_node_id": "resp12",
            "to_node_id": "resp13",
            "label": "reason:fact-detail"
        },
        {
            "id": "e25",
            "from_node_id": "resp11",
            "to_node_id": "resp14",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e26",
            "from_node_id": "resp12",
            "to_node_id": "resp14",
            "label": "reason:concept-example"
        },
        {
            "id": "e27",
            "from_node_id": "resp13",
            "to_node_id": "resp14",
            "label": "reason:fact-detail"
        },
        {
            "id": "e28",
            "from_node_id": "resp12",
            "to_node_id": "resp15",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e29",
            "from_node_id": "resp14",
            "to_node_id": "resp15",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e30",
            "from_node_id": "resp12",
            "to_node_id": "resp16",
            "label": "reason:concept-example"
        },
        {
            "id": "e31",
            "from_node_id": "resp14",
            "to_node_id": "resp16",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e32",
            "from_node_id": "resp15",
            "to_node_id": "resp16",
            "label": "evaluate:support"
        },
        {
            "id": "e33",
            "from_node_id": "resp15",
            "to_node_id": "resp17",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e34",
            "from_node_id": "resp16",
            "to_node_id": "resp17",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e35",
            "from_node_id": "resp16",
            "to_node_id": "resp18",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e36",
            "from_node_id": "resp17",
            "to_node_id": "resp18",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e37",
            "from_node_id": "resp14",
            "to_node_id": "resp19",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e38",
            "from_node_id": "resp16",
            "to_node_id": "resp19",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e39",
            "from_node_id": "resp18",
            "to_node_id": "resp19",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e40",
            "from_node_id": "resp8",
            "to_node_id": "resp20",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e41",
            "from_node_id": "resp16",
            "to_node_id": "resp20",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e42",
            "from_node_id": "resp19",
            "to_node_id": "resp20",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e43",
            "from_node_id": "resp5",
            "to_node_id": "resp21",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e44",
            "from_node_id": "resp9",
            "to_node_id": "resp21",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e45",
            "from_node_id": "resp8",
            "to_node_id": "resp22",
            "label": "evaluate:support"
        },
        {
            "id": "e46",
            "from_node_id": "resp10",
            "to_node_id": "resp22",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e47",
            "from_node_id": "resp21",
            "to_node_id": "resp22",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e48",
            "from_node_id": "resp3",
            "to_node_id": "resp23",
            "label": "reason:concept-example"
        },
        {
            "id": "e49",
            "from_node_id": "resp8",
            "to_node_id": "resp23",
            "label": "evaluate:support"
        },
        {
            "id": "e50",
            "from_node_id": "resp22",
            "to_node_id": "resp23",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e51",
            "from_node_id": "resp20",
            "to_node_id": "resp26",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e52",
            "from_node_id": "resp24",
            "to_node_id": "resp26",
            "label": "evaluate:support"
        },
        {
            "id": "e53",
            "from_node_id": "resp25",
            "to_node_id": "resp26",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e54",
            "from_node_id": "resp1",
            "to_node_id": "resp27",
            "label": "plan:plan-subplan"
        },
        {
            "id": "e55",
            "from_node_id": "resp11",
            "to_node_id": "resp27",
            "label": "plan:plan-nextplan"
        },
        {
            "id": "e56",
            "from_node_id": "resp0",
            "to_node_id": "resp28",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e57",
            "from_node_id": "resp1",
            "to_node_id": "resp28",
            "label": "reason:plan-step"
        },
        {
            "id": "e58",
            "from_node_id": "resp2",
            "to_node_id": "resp28",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e59",
            "from_node_id": "resp3",
            "to_node_id": "resp28",
            "label": "evaluate:support"
        },
        {
            "id": "e60",
            "from_node_id": "resp4",
            "to_node_id": "resp28",
            "label": "reason:fact-detail"
        },
        {
            "id": "e61",
            "from_node_id": "resp5",
            "to_node_id": "resp28",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e62",
            "from_node_id": "resp6",
            "to_node_id": "resp28",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e63",
            "from_node_id": "resp7",
            "to_node_id": "resp28",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e64",
            "from_node_id": "resp8",
            "to_node_id": "resp28",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e65",
            "from_node_id": "resp9",
            "to_node_id": "resp28",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e66",
            "from_node_id": "resp10",
            "to_node_id": "resp28",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e67",
            "from_node_id": "resp5",
            "to_node_id": "resp29",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e68",
            "from_node_id": "resp9",
            "to_node_id": "resp29",
            "label": "evaluate:uncertainty"
        },
        {
            "id": "e69",
            "from_node_id": "resp22",
            "to_node_id": "resp29",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e70",
            "from_node_id": "resp23",
            "to_node_id": "resp29",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e71",
            "from_node_id": "resp28",
            "to_node_id": "resp29",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e72",
            "from_node_id": "resp29",
            "to_node_id": "resp30",
            "label": "reason:fact-detail"
        },
        {
            "id": "e73",
            "from_node_id": "resp29",
            "to_node_id": "resp31",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e74",
            "from_node_id": "resp30",
            "to_node_id": "resp31",
            "label": "reason:fact-detail"
        },
        {
            "id": "e75",
            "from_node_id": "resp16",
            "to_node_id": "resp32",
            "label": "reason:concept-example"
        },
        {
            "id": "e76",
            "from_node_id": "resp19",
            "to_node_id": "resp32",
            "label": "reason:concept-example"
        },
        {
            "id": "e77",
            "from_node_id": "resp24",
            "to_node_id": "resp32",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e78",
            "from_node_id": "resp25",
            "to_node_id": "resp32",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e79",
            "from_node_id": "resp26",
            "to_node_id": "resp32",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e80",
            "from_node_id": "resp19",
            "to_node_id": "resp33",
            "label": "reason:concept-example"
        },
        {
            "id": "e81",
            "from_node_id": "resp24",
            "to_node_id": "resp33",
            "label": "evaluate:support"
        },
        {
            "id": "e82",
            "from_node_id": "resp32",
            "to_node_id": "resp33",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e83",
            "from_node_id": "resp24",
            "to_node_id": "resp34",
            "label": "evaluate:support"
        },
        {
            "id": "e84",
            "from_node_id": "resp32",
            "to_node_id": "resp34",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e85",
            "from_node_id": "resp33",
            "to_node_id": "resp34",
            "label": "reason:fact-detail"
        },
        {
            "id": "e86",
            "from_node_id": "resp32",
            "to_node_id": "resp35",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e87",
            "from_node_id": "resp33",
            "to_node_id": "resp35",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e88",
            "from_node_id": "resp34",
            "to_node_id": "resp35",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e89",
            "from_node_id": "resp25",
            "to_node_id": "resp36",
            "label": "reason:premise-conclusion"
        },
        {
            "id": "e90",
            "from_node_id": "resp26",
            "to_node_id": "resp36",
            "label": "reason:stmt-restatement"
        },
        {
            "id": "e91",
            "from_node_id": "resp35",
            "to_node_id": "resp36",
            "label": "reason:stmt-restatement"
        }
    ]
}